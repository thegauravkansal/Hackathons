{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the training data\n",
    "train_data = pd.read_csv('train.csv',index_col='UniqueID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.782929\n",
       "1    0.217071\n",
       "Name: loan_default, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the target feature distribution\n",
    "train_data['loan_default'].value_counts()/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Seperating date features to date,month and year\n",
    "def seperating_date(dataframe):\n",
    "    date_columns = ['Date.of.Birth', 'DisbursalDate']\n",
    "    dataframe[['date','month','year']] = dataframe['Date.of.Birth'].str.split(\"-\", expand = True)\n",
    "    dataframe[['Disbursal_date','Disbursal_month','Disbursal_year']] = dataframe['DisbursalDate'].str.split(\"-\", expand = True)\n",
    "    dataframe.drop(date_columns, axis=1, inplace= True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = seperating_date(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting below columns to months\n",
    "def converting_month(dataframe):\n",
    "    months_col = ['AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH']\n",
    "    for i in months_col:\n",
    "        dataframe[i] = dataframe[i].map(lambda x: int(x.split(\" \")[0][:-3])*12 + int(x.split(\" \")[1][:-3]))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = converting_month(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding object to label encoder\n",
    "def categorical_convert(dataframe):\n",
    "    categorical_column = 'Employment.Type'\n",
    "    dataframe[categorical_column].fillna(\"Not Given\",inplace=True)\n",
    "    dummy = pd.get_dummies(dataframe[categorical_column])\n",
    "    dataframe = pd.concat([dataframe,dummy],axis=1)\n",
    "    dataframe.drop(categorical_column,axis=1,inplace=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = categorical_convert(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Bureau History Available : 0 0\n",
      "Length : 116950\n",
      "I-Medium Risk : 571 600\n",
      "Length : 5557\n",
      "L-Very High Risk : 301 350\n",
      "Length : 1134\n",
      "A-Very Low Risk : 806 890\n",
      "Length : 14124\n",
      "Not Scored: Not Enough Info available on the customer : 17 17\n",
      "Length : 3672\n",
      "D-Very Low Risk : 706 735\n",
      "Length : 11358\n",
      "M-Very High Risk : 300 300\n",
      "Length : 8776\n",
      "B-Very Low Risk : 761 805\n",
      "Length : 9201\n",
      "C-Very Low Risk : 736 760\n",
      "Length : 16045\n",
      "E-Low Risk : 681 705\n",
      "Length : 5821\n",
      "H-Medium Risk : 601 630\n",
      "Length : 6855\n",
      "F-Low Risk : 651 680\n",
      "Length : 8485\n",
      "K-High Risk : 351 520\n",
      "Length : 8277\n",
      "Not Scored: No Activity seen on the customer (Inactive) : 16 16\n",
      "Length : 2885\n",
      "Not Scored: Sufficient History Not Available : 15 15\n",
      "Length : 3765\n",
      "Not Scored: No Updates available in last 36 months : 18 18\n",
      "Length : 1534\n",
      "G-Low Risk : 631 650\n",
      "Length : 3988\n",
      "J-High Risk : 521 570\n",
      "Length : 3748\n",
      "Not Scored: Only a Guarantor : 14 14\n",
      "Length : 976\n",
      "Not Scored: More than 50 active Accounts found : 11 11\n",
      "Length : 3\n"
     ]
    }
   ],
   "source": [
    "cols = ['PERFORM_CNS.SCORE', 'PERFORM_CNS.SCORE.DESCRIPTION']\n",
    "for i in list(train_data[cols[1]].unique()):\n",
    "    temp = sorted(set(train_data[cols[0]][train_data[cols[1]]==i].values))\n",
    "    print(i,\":\",temp[0],temp[-1])\n",
    "    print(\"Length :\",len(train_data[cols[0]][train_data[cols[1]]==i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on above input converting into labels 'PERFORM_CNS.SCORE.DESCRIPTION' column\n",
    "dict_labels = {'No Bureau History Available':0,\n",
    " 'I-Medium Risk':15,\n",
    " 'L-Very High Risk':18,\n",
    " 'A-Very Low Risk':7,\n",
    " 'Not Scored: Not Enough Info available on the customer':5,\n",
    " 'D-Very Low Risk':10,\n",
    " 'M-Very High Risk':19,\n",
    " 'B-Very Low Risk':8,\n",
    " 'C-Very Low Risk':9,\n",
    " 'E-Low Risk':11,\n",
    " 'H-Medium Risk':14,\n",
    " 'F-Low Risk':12,\n",
    " 'K-High Risk':17,\n",
    " 'Not Scored: No Activity seen on the customer (Inactive)':4,\n",
    " 'Not Scored: Sufficient History Not Available':3,\n",
    " 'Not Scored: No Updates available in last 36 months':6,\n",
    " 'G-Low Risk':13,\n",
    " 'J-High Risk':16,\n",
    " 'Not Scored: Only a Guarantor':2,\n",
    " 'Not Scored: More than 50 active Accounts found':1}\n",
    "\n",
    "def labelling(dataset):\n",
    "    dataset['PERFORM_CNS.SCORE.DESCRIPTION'].replace(dict_labels,inplace=True)\n",
    "    dataset['PERFORM_CNS.SCORE.DESCRIPTION'] = dataset['PERFORM_CNS.SCORE.DESCRIPTION'].astype('object')\n",
    "    dataset.drop('PERFORM_CNS.SCORE',axis=1, inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = labelling(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['loan_default'].copy()\n",
    "train_data.drop('loan_default',axis=1,inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,y,stratify=y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(X_train,y_train):\n",
    "    score_list = []\n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state = 5)\n",
    "    i = 1\n",
    "    for train, test in cv.split(X_train, y_train):\n",
    "        classifier = XGBClassifier(random_state=42,scale_pos_weight=sum(y_train[test]==0)/sum(y_train[test]==1))\n",
    "        classifier.fit(X_train[train,:], y_train[train,])\n",
    "        pred = classifier.predict(X_train[test,:])\n",
    "        roc_score = roc_auc_score(pred,y_train[test])\n",
    "        print(\"Cross Validation: \",i,\" Score:\", roc_score)\n",
    "        i += 1\n",
    "        score_list.append(roc_score)\n",
    "    return mean(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITIN\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation:  1  Score: 0.5789185850352582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITIN\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation:  2  Score: 0.5788263228570262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITIN\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation:  3  Score: 0.582165775918117\n",
      "Cross Validation:  4  Score: 0.5820286310618715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITIN\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "score = modelling(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_bqCt9Pv.csv',index_col='UniqueID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = seperating_date(test_data)\n",
    "test_data = converting_month(test_data)\n",
    "test_data = categorical_convert(test_data)\n",
    "test_data = labelling(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[train_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(random_state=42,scale_pos_weight=sum(y[y==0])/sum(y[y==1]))\n",
    "classifier.fit(train_data.values,y)\n",
    "pred = classifier.predict_proba(test_data.values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(pred,index=test_data.index,columns=['loan_default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
