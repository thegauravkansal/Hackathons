{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Loading the training data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "#Loading the test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data=test_data.rename(columns={'actual _credit_score':'actual_credit_score'})\n",
    "\n",
    "y=train_data.total_sales\n",
    "\n",
    "# Dropping the 'Criminal' columm from training data\n",
    "X_train = train_data.drop('total_sales',axis=1)\n",
    "\n",
    "# Columns list in training data\n",
    "columns_list = X_train.columns\n",
    "\n",
    "# Check if columns had any missing values\n",
    "columns_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "# Columns does not have any missing values so we don't use imputer\n",
    "print(columns_with_missing)\n",
    "\n",
    "# Check if training file has any categorical data\n",
    "non_categorical_predictors = X_train.select_dtypes(include=['object'])\n",
    "#print(non_categorical_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [344, 44]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-2fb48dd7a303>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpredictors_without_categoricals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_predictors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmae_one_hot_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_encoded_training_predictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean Abslute Error with One-Hot Encoding: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmae_one_hot_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-2fb48dd7a303>\u001b[0m in \u001b[0;36mget_mae\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      8\u001b[0m     return -1 * cross_val_score(RandomForestRegressor(50), \n\u001b[0;32m      9\u001b[0m                                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                 scoring = 'neg_mean_absolute_error').mean()\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpredictors_without_categoricals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_predictors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [344, 44]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "one_hot_encoded_training_predictors = pd.get_dummies(training_predictors)\n",
    "\n",
    "def get_mae(X, y):\n",
    "    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n",
    "    return -1 * cross_val_score(RandomForestRegressor(50), \n",
    "                                X, y, \n",
    "                                scoring = 'neg_mean_absolute_error').mean()\n",
    "\n",
    "predictors_without_categoricals = training_predictors.select_dtypes(exclude=['object'])\n",
    "mae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, y)\n",
    "\n",
    "print('Mean Abslute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['store_location', 'time_zone', 'credit_score', 'credit_score_range', 'outlet_no', 'business_type', 'zip', 'avg_age', 'blue_collar', 'white_collar', 'female', 'male', 'total_household_size ', 'total_household_income', 'latitude', 'longitude', 'employee_size', 'actual_credit_score']\n"
     ]
    }
   ],
   "source": [
    "cardinality_cols = [cname for cname in X_train.columns \n",
    "                    if X_train[cname].nunique()<10 and X_train[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in X_train.columns \n",
    "                    if X_train[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_columns =cardinality_cols + numerical_cols\n",
    "drop_column=['outlet_no','zip','avg_age','blue_collar','female','male','latitude','longitude','employee_size',\n",
    "             'actual_credt_score']\n",
    "print(my_columns)\n",
    "training_predictors = X_train[my_columns]\n",
    "testing_predictors = test_data[my_columns]\n",
    "\n",
    "one_hot_encoded_training_predictors = pd.get_dummies(training_predictors)\n",
    "one_hot_encoded_test_predictors = pd.get_dummies(testing_predictors)\n",
    "\n",
    "final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n",
    "                                                                    join='left', \n",
    "                                                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4459    476    501    705    774   1367   1610    524    512   1436\n",
      "    770   4242   1438   1821    507    508   1499   1286   1826   4816\n",
      "   1612    542   2311    516   1659   2199    811   6650   1639    693\n",
      "    491    916 103479   1514   3435   3933   1382   1846   4013   9472\n",
      "    511  14130   1720   1691   3303   4752   1933   1681   5945   1428\n",
      " 108253  11212    765  16493   1420   1470   1805   3769    543    943\n",
      "    727  16983  20109   5362   1982  12631  21034   1392   7817   7312\n",
      "  16529   8146   5730    850  11060   3533   7442  11460   3601  10499\n",
      "   1640   3134   9926    579   3885  17877  37997    525   6379  14530\n",
      "  15854    731    534    631    554    656    796    725   1035   1600\n",
      "    512    531  10648   1477   1655    692   1233  76131  12173 314762\n",
      "   9004   1602   1914   7579   9025   7787    825    555 755591   1243\n",
      "    533  11302   1393  10334   4760    462   1422    522    535   3126\n",
      "  21750   2204    512    523   1595   1633   1831   1810   1704   1724\n",
      "   1041   1941   5338    533    760   1398   1446   1605   6697   3946\n",
      "    530    513   1872    508  19608   3596    592    464   1546   1844\n",
      "    491   1704   1480   3259   8664   1755   1752   7258    613   4651\n",
      "   1557    535    554  12442   8998    682  11503   1213  11280   8972\n",
      "  10366  14570  11015    487   4287    716   1845    837  22860   6539\n",
      "   6539 196027    754   1231  11311   9992  15729   1315   3732  66330\n",
      "   9216    573    647  15423    631   9603   3810    631    814    803\n",
      "   3370  71692  43986    764    884   1283  78641   1310  12052   1046\n",
      "    507   1581   1761    548    502    514    516   1554  14926   4242\n",
      "   1786    543   7107   5864    883   4879    650   2249    516   4869\n",
      "    622    792    549    517   1637  17456  75049    696   4353    520\n",
      "  71539  11945    535    534   3789]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "my_model = RandomForestRegressor()\n",
    "my_model.fit(final_train, y)\n",
    "\n",
    "predicted_prices = my_model.predict(final_test)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "value=predicted_prices.astype(int)\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'outlet_no': test_data.outlet_no, 'total_sales_actual': value})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True  True  True False  True  True False False  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "[ 1 25  1  1  1  2  1  1  4  3  1  1  1  1  5 21 26 32 28 19  9 18 15  6\n",
      " 24 16 12 14 17  8 27 13 29 33 34 30 22 20  7 11 10 23 35 31]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_iris()\n",
    "svm = RandomForestRegressor()# create the RFE model for the svm classifier \n",
    "# and select attributes    \n",
    "rfe = RFE(svm, 10) #71\n",
    "rfe = rfe.fit(final_train, y)\n",
    "# print summaries for the selection of attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 1 outlet_no\n",
      "False 25 business_type\n",
      "True 1 zip\n",
      "True 1 avg_age\n",
      "True 1 blue_collar\n",
      "False 2 white_collar\n",
      "True 1 female\n",
      "True 1 male\n",
      "False 4 total_household_size \n",
      "False 3 total_household_income\n",
      "True 1 latitude\n",
      "True 1 longitude\n",
      "True 1 employee_size\n",
      "True 1 actual_credit_score\n",
      "False 5 store_location_AT-WORK\n",
      "False 21 store_location_EATING & DRINKING\n",
      "False 26 store_location_EDUCATIONAL\n",
      "False 32 store_location_ENTERTAINMENT/RECREATION/LEISURE\n",
      "False 28 store_location_GROCERY SHOPPING\n",
      "False 19 store_location_OTHER SHOPPING & SERVICES\n",
      "False 9 store_location_THIRD PARTY (NON-CONSUMER)\n",
      "False 18 store_location_TRAVEL/TRANSPORTATION/HOSPITALITY\n",
      "False 15 time_zone_CST\n",
      "False 6 time_zone_EST\n",
      "False 24 time_zone_MST\n",
      "False 16 time_zone_PST\n",
      "False 12 credit_score_A\n",
      "False 14 credit_score_A+\n",
      "False 17 credit_score_B\n",
      "False 8 credit_score_B+\n",
      "False 27 credit_score_C\n",
      "False 13 credit_score_C+\n",
      "False 29 credit_score_I\n",
      "False 33 credit_score_P\n",
      "False 34 credit_score_U\n",
      "False 30 credit_score_range_70 TO 74\n",
      "False 22 credit_score_range_75 TO 79\n",
      "False 20 credit_score_range_80 TO 84\n",
      "False 7 credit_score_range_85 TO 89\n",
      "False 11 credit_score_range_90 TO 94\n",
      "False 10 credit_score_range_95 TO 100\n",
      "False 23 credit_score_range_INSTITUTION\n",
      "False 35 credit_score_range_LESS THAN 70\n",
      "False 31 credit_score_range_PROFESSIONAL INDIVIDUAL\n"
     ]
    }
   ],
   "source": [
    "y=final_train.columns\n",
    "for i in range(0,len(y)):\n",
    "    print(rfe.support_[i],rfe.ranking_[i],y[i])\n",
    "\n",
    "drop_column=['outlet_no','zip','avg_age','blue_collar','female','male','latitude','longitude','employee_size',\n",
    "             'actual_credt_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
